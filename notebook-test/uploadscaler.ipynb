{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "42f9b6ff-fbe3-4345-9077-8a04bca225a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.00043589 -0.2046263   0.         ...  2.75284929  0.88885052\n",
      "   0.83495712]\n",
      " [-1.7870665  -0.2046263   0.         ...  1.05786348  1.28040239\n",
      "  -0.18877292]\n",
      " [ 0.63967228 -0.2046263   0.         ... -0.63712232 -1.55443316\n",
      "  -0.18877292]\n",
      " ...\n",
      " [ 0.63967228 -0.2046263   0.         ... -0.63712232 -0.17617057\n",
      "  -0.18877292]\n",
      " [ 0.33632993 -0.2046263   0.         ...  1.05786348 -0.36411547\n",
      "  -1.21250296]\n",
      " [ 0.63967228 -0.2046263   0.         ...  1.05786348 -0.45808792\n",
      "  -0.18877292]]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'transform'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 40\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[1;32m     39\u001b[0m data_dict \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2022\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124morigin\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirstHand\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmileage\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2150\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124menergy\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgearbox\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m4\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdoors\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m4\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mratedHorsePower\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m100\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpowerDIN\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m190\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcritAir\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mco2\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m132\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mowners\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2.0\u001b[39m}]\n\u001b[0;32m---> 40\u001b[0m \u001b[43mMLP_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[23], line 30\u001b[0m, in \u001b[0;36mMLP_prediction\u001b[0;34m(data_dict_list)\u001b[0m\n\u001b[1;32m     28\u001b[0m df_input \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(input_data)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Transform the input data using the loaded scaler\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m scaled_input_data \u001b[38;5;241m=\u001b[39m \u001b[43mloaded_scaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m(df_input)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28mprint\u001b[39m(scaled_input_data)\n\u001b[1;32m     32\u001b[0m y_predict \u001b[38;5;241m=\u001b[39m loaded_model\u001b[38;5;241m.\u001b[39mpredict(scaled_input_data)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'transform'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import joblib\n",
    "from django.templatetags.static import static\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, MinMaxScaler \n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import os\n",
    "\n",
    "def MLP_prediction(data_dict_list):\n",
    "\n",
    "    model_url = 'rf_model.joblib'\n",
    "    loaded_model = joblib.load(model_url)\n",
    "\n",
    "    scaler_url = 'scaler2.joblib'\n",
    "    loaded_scaler = joblib.load(scaler_url)\n",
    "    print(loaded_scaler)\n",
    "    data_dict = data_dict_list[0]\n",
    "    input_values = [data_dict['year'], data_dict['origin'], data_dict['firstHand'],\n",
    "                    data_dict['mileage'], data_dict['energy'], data_dict['gearbox'],\n",
    "                    data_dict['doors'], data_dict['ratedHorsePower'], data_dict['powerDIN'],\n",
    "                    data_dict['critAir'], data_dict['co2'], data_dict['owners']]\n",
    "    \n",
    "    # Convert the values to float\n",
    "    input_data = np.array(input_values, dtype=float) \n",
    "    input_data = input_data.reshape(1, -1)\n",
    "\n",
    "    # Transform the input data using the loaded scaler\n",
    "    scaled_input_data = loaded_scaler.transform(input_data)\n",
    "    print(scaled_input_data)\n",
    "    y_predict = loaded_model.predict(scaled_input_data)\n",
    "\n",
    "    response = {\n",
    "        \"prediction_price\" : y_predict[0]\n",
    "    }   \n",
    "    return response\n",
    "\n",
    "data_dict = [{'year': 2022, 'origin': 1, 'firstHand': 0, 'mileage': 2150, 'energy': 0, 'gearbox': 4, 'doors': 4, 'ratedHorsePower': 100, 'powerDIN': 190, 'critAir': 2, 'co2': 132, 'owners': 2.0}]\n",
    "MLP_prediction(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8dcaee68-612e-4665-ab02-825cd8930dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.022e+03 1.000e+00 0.000e+00 1.200e+02 0.000e+00 1.000e+00 5.000e+00\n",
      "  1.000e+01 1.900e+02 5.000e+00 1.000e+00 3.000e+00]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[2.022e+03 1.000e+00 0.000e+00 1.200e+02 0.000e+00 1.000e+00 5.000e+00\n 1.000e+01 1.900e+02 5.000e+00 1.000e+00 3.000e+00].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n\u001b[1;32m     30\u001b[0m data_dict \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124myear\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m2022\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124morigin\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfirstHand\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmileage\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m120\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124menergy\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgearbox\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdoors\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m5\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mratedHorsePower\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m10\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpowerDIN\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m190\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcritAir\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m5\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mco2\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mowners\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;241m3.0\u001b[39m}]\n\u001b[0;32m---> 31\u001b[0m \u001b[43mMLP_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[65], line 22\u001b[0m, in \u001b[0;36mMLP_prediction\u001b[0;34m(data_dict_list)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(input_data2)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Transform the input data using the loaded scaler\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m scaled_input_data \u001b[38;5;241m=\u001b[39m \u001b[43mloaded_scaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m y_predict \u001b[38;5;241m=\u001b[39m loaded_model\u001b[38;5;241m.\u001b[39mpredict(scaled_input_data)\n\u001b[1;32m     25\u001b[0m response \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprediction_price\u001b[39m\u001b[38;5;124m\"\u001b[39m : y_predict[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     27\u001b[0m }   \n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    146\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:514\u001b[0m, in \u001b[0;36mMinMaxScaler.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Scale features of X according to feature_range.\u001b[39;00m\n\u001b[1;32m    501\u001b[0m \n\u001b[1;32m    502\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;124;03m    Transformed data.\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    512\u001b[0m check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 514\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    520\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    522\u001b[0m X \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_\n\u001b[1;32m    523\u001b[0m X \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmin_\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/base.py:604\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    602\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 604\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    606\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/sklearn/utils/validation.py:940\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    938\u001b[0m     \u001b[38;5;66;03m# If input is 1D raise error\u001b[39;00m\n\u001b[1;32m    939\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 940\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    941\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124marray=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    942\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    943\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    944\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mif it contains a single sample.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[1;32m    945\u001b[0m         )\n\u001b[1;32m    947\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype_numeric \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(array\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkind\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUSV\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    948\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    949\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    950\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    951\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[2.022e+03 1.000e+00 0.000e+00 1.200e+02 0.000e+00 1.000e+00 5.000e+00\n 1.000e+01 1.900e+02 5.000e+00 1.000e+00 3.000e+00].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "def MLP_prediction(data_dict_list):\n",
    "\n",
    "    model_url = 'random_forest.joblib'\n",
    "    loaded_model = joblib.load(model_url)\n",
    "\n",
    "    scaler_url = 'scaler2-1.joblib'\n",
    "    loaded_scaler = joblib.load(scaler_url)\n",
    "\n",
    "    data_dict = data_dict_list[0]\n",
    "    input_values = [data_dict['year'], data_dict['origin'], data_dict['firstHand'],\n",
    "                    data_dict['mileage'], data_dict['energy'], data_dict['gearbox'],\n",
    "                    data_dict['doors'], data_dict['ratedHorsePower'], data_dict['powerDIN'],\n",
    "                    data_dict['critAir'], data_dict['co2'], data_dict['owners']]\n",
    "    \n",
    "    # Convert the values to float\n",
    "    input_data = np.array(input_values, dtype=float) \n",
    "    input_data2 = input_data.reshape(1, -1)\n",
    "    \n",
    "    print(input_data2)\n",
    "\n",
    "    # Transform the input data using the loaded scaler\n",
    "    scaled_input_data = loaded_scaler.transform(input_data)\n",
    "    y_predict = loaded_model.predict(scaled_input_data)\n",
    "\n",
    "    response = {\n",
    "        \"prediction_price\" : y_predict[0]\n",
    "    }   \n",
    "    return response\n",
    "\n",
    "data_dict = [{'year': 2022, 'origin': 1, 'firstHand': 0, 'mileage': 120, 'energy': 0, 'gearbox': 1, 'doors': 5, 'ratedHorsePower': 10, 'powerDIN': 190, 'critAir': 5, 'co2': 1, 'owners': 3.0}]\n",
    "MLP_prediction(data_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd51d1e3-f7c5-4301-a0c3-14ac283d88d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
